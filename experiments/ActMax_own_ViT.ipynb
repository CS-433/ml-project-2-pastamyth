{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/mlproj2_new/ActMax-Optimizer-Dev\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.vit_model import VisionTransformer\n",
    "from transformers.tf_exp import TransformerEvolution\n",
    "from core.insilico_exps import resize_and_pad_tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = './transformers/model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dic = torch.load(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs={'embed_dim': 256,\n",
    "'hidden_dim': 512,\n",
    "'num_heads': 8,\n",
    "'num_layers': 6,\n",
    "'patch_size': 4,\n",
    "'num_channels': 3,\n",
    "'num_patches': 64,\n",
    "'num_classes': 10,\n",
    "'dropout': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = VisionTransformer(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit.load_state_dict(model_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tf_exp import TransformerScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerScorer('own_vit', imgpix=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unit = (\"own_vit\", \".mlp_head.Linear1\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space dimension: 4096, Population size: 40, Select size:20, Optimization Parameters:\n",
      "Initial sigma: 3.000\n",
      "cc=0.001, cs=0.050, c1=0.000 damps=1.050\n"
     ]
    }
   ],
   "source": [
    "exp = TransformerEvolution(model_unit, imgsize=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synth img scores: mean -3.488 +- std 0.000\n",
      "step 0  time: total 0.64s | GAN visualize 0.57s   Transformers score 0.01s   optimizer step 0.06s\n",
      "sigma: 2.90\n",
      "synth img scores: mean -3.395 +- std 3.561\n",
      "step 1  time: total 0.16s | GAN visualize 0.08s   Transformers score 0.03s   optimizer step 0.04s\n",
      "sigma: 2.83\n",
      "synth img scores: mean -2.267 +- std 3.554\n",
      "step 2  time: total 0.21s | GAN visualize 0.09s   Transformers score 0.01s   optimizer step 0.10s\n",
      "sigma: 2.76\n",
      "synth img scores: mean -1.108 +- std 3.641\n",
      "step 3  time: total 0.13s | GAN visualize 0.06s   Transformers score 0.03s   optimizer step 0.04s\n",
      "sigma: 2.71\n",
      "synth img scores: mean -0.217 +- std 3.842\n",
      "step 4  time: total 0.12s | GAN visualize 0.06s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.66\n",
      "synth img scores: mean 2.734 +- std 3.052\n",
      "step 5  time: total 0.12s | GAN visualize 0.06s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.62\n",
      "synth img scores: mean 3.462 +- std 3.428\n",
      "step 6  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.59\n",
      "synth img scores: mean 4.909 +- std 3.258\n",
      "step 7  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.56\n",
      "synth img scores: mean 5.881 +- std 3.382\n",
      "step 8  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.53\n",
      "synth img scores: mean 5.231 +- std 3.235\n",
      "step 9  time: total 0.12s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.50\n",
      "synth img scores: mean 6.760 +- std 3.050\n",
      "step 10  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.48\n",
      "A, Ainv update! Time cost: 0.38 s\n",
      "synth img scores: mean 7.876 +- std 3.219\n",
      "step 11  time: total 0.48s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.42s\n",
      "sigma: 2.47\n",
      "synth img scores: mean 8.693 +- std 3.316\n",
      "step 12  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.45\n",
      "synth img scores: mean 9.271 +- std 2.667\n",
      "step 13  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.44\n",
      "synth img scores: mean 10.427 +- std 2.657\n",
      "step 14  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.42\n",
      "synth img scores: mean 10.746 +- std 2.434\n",
      "step 15  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.41\n",
      "synth img scores: mean 11.005 +- std 2.717\n",
      "step 16  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.40\n",
      "synth img scores: mean 11.861 +- std 2.407\n",
      "step 17  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.39\n",
      "synth img scores: mean 12.813 +- std 2.775\n",
      "step 18  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.38\n",
      "synth img scores: mean 13.477 +- std 1.707\n",
      "step 19  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.37\n",
      "synth img scores: mean 13.930 +- std 1.772\n",
      "step 20  time: total 0.12s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.37\n",
      "synth img scores: mean 14.195 +- std 2.190\n",
      "step 21  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.36\n",
      "A, Ainv update! Time cost: 0.41 s\n",
      "synth img scores: mean 15.064 +- std 1.791\n",
      "step 22  time: total 0.51s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.45s\n",
      "sigma: 2.36\n",
      "synth img scores: mean 14.545 +- std 2.047\n",
      "step 23  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.35\n",
      "synth img scores: mean 15.304 +- std 1.727\n",
      "step 24  time: total 0.12s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.35\n",
      "synth img scores: mean 15.018 +- std 2.038\n",
      "step 25  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.35\n",
      "synth img scores: mean 16.032 +- std 2.011\n",
      "step 26  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.35\n",
      "synth img scores: mean 16.378 +- std 1.501\n",
      "step 27  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.34\n",
      "synth img scores: mean 16.562 +- std 1.422\n",
      "step 28  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.34\n",
      "synth img scores: mean 16.470 +- std 1.417\n",
      "step 29  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.34\n",
      "synth img scores: mean 16.659 +- std 1.393\n",
      "step 30  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.34\n",
      "synth img scores: mean 16.235 +- std 1.543\n",
      "step 31  time: total 0.12s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 16.422 +- std 1.258\n",
      "step 32  time: total 0.12s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.33\n",
      "A, Ainv update! Time cost: 0.42 s\n",
      "synth img scores: mean 17.132 +- std 1.261\n",
      "step 33  time: total 0.54s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.46s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 16.396 +- std 2.095\n",
      "step 34  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 16.947 +- std 1.340\n",
      "step 35  time: total 0.16s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.08s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 16.662 +- std 1.572\n",
      "step 36  time: total 0.12s | GAN visualize 0.06s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 17.026 +- std 1.413\n",
      "step 37  time: total 0.16s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.10s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 17.431 +- std 1.521\n",
      "step 38  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 17.638 +- std 1.344\n",
      "step 39  time: total 0.13s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 17.158 +- std 1.974\n",
      "step 40  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 17.504 +- std 1.099\n",
      "step 41  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 17.498 +- std 1.459\n",
      "step 42  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 17.622 +- std 1.084\n",
      "step 43  time: total 0.13s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.32\n",
      "A, Ainv update! Time cost: 0.42 s\n",
      "synth img scores: mean 17.394 +- std 1.395\n",
      "step 44  time: total 0.54s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.46s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 17.708 +- std 1.546\n",
      "step 45  time: total 0.11s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.33\n",
      "synth img scores: mean 17.539 +- std 1.634\n",
      "step 46  time: total 0.11s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 18.111 +- std 1.136\n",
      "step 47  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 18.041 +- std 1.065\n",
      "step 48  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 18.287 +- std 1.144\n",
      "step 49  time: total 0.11s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 18.452 +- std 1.425\n",
      "step 50  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 18.115 +- std 1.133\n",
      "step 51  time: total 0.12s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 18.415 +- std 1.270\n",
      "step 52  time: total 0.11s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 18.527 +- std 1.328\n",
      "step 53  time: total 0.13s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 18.656 +- std 1.177\n",
      "step 54  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "A, Ainv update! Time cost: 0.43 s\n",
      "synth img scores: mean 18.764 +- std 1.198\n",
      "step 55  time: total 0.53s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.47s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 18.867 +- std 1.097\n",
      "step 56  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.02s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 18.827 +- std 1.157\n",
      "step 57  time: total 0.12s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.038 +- std 1.137\n",
      "step 58  time: total 0.11s | GAN visualize 0.07s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 18.922 +- std 0.988\n",
      "step 59  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.517 +- std 0.792\n",
      "step 60  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.487 +- std 0.915\n",
      "step 61  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.173 +- std 0.994\n",
      "step 62  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.148 +- std 1.097\n",
      "step 63  time: total 0.11s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.05s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.339 +- std 0.841\n",
      "step 64  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.491 +- std 0.787\n",
      "step 65  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "A, Ainv update! Time cost: 0.41 s\n",
      "synth img scores: mean 19.295 +- std 1.039\n",
      "step 66  time: total 0.51s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.45s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.483 +- std 1.146\n",
      "step 67  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.783 +- std 0.825\n",
      "step 68  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.516 +- std 1.219\n",
      "step 69  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.810 +- std 0.864\n",
      "step 70  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.175 +- std 1.388\n",
      "step 71  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.913 +- std 0.951\n",
      "step 72  time: total 0.09s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 20.102 +- std 0.509\n",
      "step 73  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.703 +- std 0.897\n",
      "step 74  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.586 +- std 0.884\n",
      "step 75  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.513 +- std 1.192\n",
      "step 76  time: total 0.09s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "A, Ainv update! Time cost: 0.41 s\n",
      "synth img scores: mean 19.810 +- std 0.951\n",
      "step 77  time: total 0.51s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.45s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.634 +- std 1.047\n",
      "step 78  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.780 +- std 0.912\n",
      "step 79  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.312 +- std 1.318\n",
      "step 80  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.846 +- std 0.787\n",
      "step 81  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.886 +- std 0.885\n",
      "step 82  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.909 +- std 0.762\n",
      "step 83  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 19.915 +- std 0.929\n",
      "step 84  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 20.123 +- std 1.108\n",
      "step 85  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 20.180 +- std 0.814\n",
      "step 86  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 20.263 +- std 0.886\n",
      "step 87  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.02s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "A, Ainv update! Time cost: 0.42 s\n",
      "synth img scores: mean 20.288 +- std 0.694\n",
      "step 88  time: total 0.52s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.46s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 20.415 +- std 0.732\n",
      "step 89  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 20.383 +- std 1.162\n",
      "step 90  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 20.369 +- std 0.696\n",
      "step 91  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "synth img scores: mean 20.178 +- std 0.935\n",
      "step 92  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 20.483 +- std 0.826\n",
      "step 93  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 20.344 +- std 0.720\n",
      "step 94  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 20.204 +- std 0.727\n",
      "step 95  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 20.018 +- std 0.953\n",
      "step 96  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 20.429 +- std 0.621\n",
      "step 97  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.32\n",
      "synth img scores: mean 20.471 +- std 0.660\n",
      "step 98  time: total 0.10s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.04s\n",
      "sigma: 2.31\n",
      "A, Ainv update! Time cost: 0.41 s\n",
      "synth img scores: mean 20.525 +- std 0.773\n",
      "step 99  time: total 0.51s | GAN visualize 0.05s   Transformers score 0.01s   optimizer step 0.45s\n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(exp.scores_all)\n",
    "select_code = exp.codes_all[idx : idx + 1, :]\n",
    "score_select = exp.scores_all[idx]\n",
    "img_select = exp.render_tsr(select_code)\n",
    "resize_select = resize_and_pad_tsr(img_select, exp.imgsize, exp.corner, canvas_size=(32, 32))\n",
    "resize_select = resize_select.cpu().squeeze().permute((1, 2, 0)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(resize_select)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test super activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR10 dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:33<00:00, 534.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get a certain class of images\n",
    "class_idx = 0\n",
    "airplanes = []\n",
    "for (x, y) in tqdm(train_loader):\n",
    "    if y == class_idx:\n",
    "        airplanes.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "airplanes_tsr = torch.cat(airplanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the scores of the images\n",
    "from transformers.tf_exp import TransformerScorer\n",
    "model = TransformerScorer('own_vit', imgpix=32)\n",
    "model.select_unit(model_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.score_tsr(airplanes_tsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.85589981])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the score of the generated image\n",
    "syn_tsr = torch.Tensor(resize_select).permute((2, 0, 1)).unsqueeze(0)\n",
    "syn_score = model.score_tsr(syn_tsr)\n",
    "syn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scores of the natural images into a csv file\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(scores, columns=['nature_score'])\n",
    "df.to_csv('./results/own_vit/airplane_own_vit_nature.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
